{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from supabase import create_client\n",
    "from langchain_community.vectorstores import SupabaseVectorStore\n",
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize core components\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "supabase_url = os.getenv(\"SUPABASE_URL\")\n",
    "supabase_key = os.getenv(\"SUPABASE_SERVICE_KEY\")\n",
    "supabase_client = create_client(supabase_url, supabase_key)\n",
    "\n",
    "# Initialize LLM and embeddings\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", streaming=True)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "vector_store = SupabaseVectorStore(\n",
    "    client=supabase_client,\n",
    "    embedding=embeddings,\n",
    "    table_name=\"documents\",  # Replace with your desired table name\n",
    "    query_name=\"match_documents\"  # Replace with your desired query name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# Define prompt for question-answering\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert AI assistant tasked with creating comprehensive reports. When generating reports:\n",
    "    - Start with a brief executive summary\n",
    "    - Organize information into clear sections with headings\n",
    "    - Include relevant examples and explanations\n",
    "    - Use bullet points and numbered lists where appropriate\n",
    "    - Synthesize information from multiple sources in the context\n",
    "    - Maintain a professional, analytical tone\n",
    "    - Conclude with key takeaways\n",
    "    \n",
    "    Base your report ONLY on the provided context.\"\"\"),\n",
    "    (\"human\", \"Using the following context, generate a detailed report about: {question}\\n\\nContext: {context}\")\n",
    "])\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "# Modify retrieve function for broader context\n",
    "def retrieve(state: State):\n",
    "    # Get more documents for comprehensive coverage\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"], k=6)\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    \n",
    "    # Create streaming response\n",
    "    stream = llm.stream(messages)\n",
    "    \n",
    "    # Initialize response content\n",
    "    response_content = \"\"\n",
    "    \n",
    "    # Process stream chunks\n",
    "    for chunk in stream:\n",
    "        if chunk.content is not None:\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            response_content += chunk.content\n",
    "            \n",
    "    return {\"answer\": response_content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task decomposition is the process of breaking down a complicated task into smaller, more manageable steps. This can be achieved through techniques like Chain of Thought (CoT), where the model is prompted to think step by step, or by utilizing task-specific instructions. It allows for improved problem-solving by creating a structured approach to address each component of the task.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Report on Task Decomposition in Software Development\n",
      "\n",
      "## Executive Summary\n",
      "Task decomposition is a critical practice in software development, especially when dealing with complex problems. This report will explore the concept of task decomposition, focusing on how it can improve problem-solving efficiency by breaking down larger tasks into more manageable components. We will discuss the Chain of Thought (CoT) prompting technique and its relevance, as well as the methodology for creating a structured coding architecture that facilitates this process.\n",
      "\n",
      "## 1. Introduction to Task Decomposition\n",
      "Task decomposition refers to the systematic breakdown of a complex task into simpler, more manageable subtasks. This process not only simplifies the execution of the task but also clarifies the necessary steps and helps in planning and organizing the workflow.\n",
      "\n",
      "### 1.1 Importance\n",
      "- **Manageability**: Smaller tasks are easier to manage and keep track of.\n",
      "- **Clarity**: Decomposing tasks provides clear linear steps, making it easier for developers to understand the requirements.\n",
      "- **Cost and Time Efficiency**: Simplified tasks often require less time and fewer resources to complete.\n",
      "\n",
      "## 2. Chain of Thought (CoT) Prompting\n",
      "The Chain of Thought (CoT) prompting technique is a process designed to enhance a model's performance on complex tasks by encouraging step-by-step reasoning.\n",
      "\n",
      "### 2.1 How CoT Works\n",
      "- **Thinking Step by Step**: By breaking down tasks into smaller pieces, the model can better utilize its capabilities and reach accurate conclusions.\n",
      "- **Interpreting Models**: CoT provides insight into the model's thought processes, allowing developers to understand the decision-making criteria.\n",
      "\n",
      "### 2.2 Application in Task Decomposition\n",
      "- CoT can transform large, daunting tasks into smaller segments:\n",
      "  - Identify the main objective of the task.\n",
      "  - Divide that objective into key aspects.\n",
      "  - Break down those aspects into actionable steps.\n",
      "\n",
      "## 3. Implementation of Task Decomposition in Code Architecture\n",
      "To effectively implement task decomposition in code development, it is crucial to define core classes, functions, and methods that facilitate this process. \n",
      "\n",
      "### 3.1 Core Components\n",
      "The following are core components necessary for implementing a well-organized coding architecture:\n",
      "\n",
      "1. **Core Classes**:\n",
      "   - `TaskManager`: Manages and oversees the entire task decomposition process.\n",
      "   - `Subtask`: Represents a smaller component of a larger task.\n",
      "   - `TaskLogger`: Logs the progress and state of the tasks.\n",
      "\n",
      "2. **Core Methods**:\n",
      "   - `decompose_task(task)`: Takes a large task and returns a list of subtasks.\n",
      "   - `execute_subtask(subtask)`: Executes a given subtask and returns the result.\n",
      "   - `log_progress(task)`: Records the current state of task execution.\n",
      "\n",
      "### 3.2 Entrypoint Architecture\n",
      "The entrypoint architecture not only sets the requirements for task decomposition but also follows a specific file structure for organization.\n",
      "\n",
      "#### 3.2.1 File Structure Overview\n",
      "- `main.py`: The entrypoint of the application.\n",
      "- `task_manager.py`: Contains the `TaskManager` class and its methods.\n",
      "- `subtask.py`: Defines the `Subtask` class and its functionalities.\n",
      "- `task_logger.py`: Implements logging mechanisms.\n",
      "\n",
      "### 3.3 File Contents\n",
      "The actual code implementation follows a strict markdown format:\n",
      "\n",
      "#### 3.3.1 `main.py`\n",
      "```python\n",
      "# FILENAME: main.py\n",
      "# LANG: python\n",
      "\n",
      "from task_manager import TaskManager\n",
      "\n",
      "def main():\n",
      "    task = \"Implement a new feature\"\n",
      "    task_manager = TaskManager()\n",
      "    task_manager.decompose_task(task)\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "```\n",
      "\n",
      "#### 3.3.2 `task_manager.py`\n",
      "```python\n",
      "# FILENAME: task_manager.py\n",
      "# LANG: python\n",
      "\n",
      "class TaskManager:\n",
      "    def decompose_task(self, task):\n",
      "        # Logic for decomposing the task\n",
      "        print(f\"Decomposing task: {task}\")\n",
      "        # Return a list of subtasks\n",
      "        return [\"Subtask 1\", \"Subtask 2\"]\n",
      "\n",
      "    def execute_subtask(self, subtask):\n",
      "        # Logic for executing the subtask\n",
      "        print(f\"Executing {subtask}\")\n",
      "```\n",
      "\n",
      "#### 3.3.3 `subtask.py`\n",
      "```python\n",
      "# FILENAME: subtask.py\n",
      "# LANG: python\n",
      "\n",
      "class Subtask:\n",
      "    def __init__(self, name):\n",
      "        self.name = name\n",
      "    \n",
      "    def perform(self):\n",
      "        # Logic to perform the subtask\n",
      "        print(f\"Performing subtask: {self.name}\")\n",
      "```\n",
      "\n",
      "#### 3.3.4 `task_logger.py`\n",
      "```python\n",
      "# FILENAME: task_logger.py\n",
      "# LANG: python\n",
      "\n",
      "class TaskLogger:\n",
      "    def log_progress(self, task):\n",
      "        # Logic to log progress\n",
      "        print(f\"Logging progress for: {task}\")\n",
      "```\n",
      "\n",
      "## 4. Conclusion and Key Takeaways\n",
      "Task decomposition plays a vital role in software development, particularly for complex applications. The integration of Chain of Thought (CoT) reasoning can significantly enhance the process of breaking down tasks into simpler components. This approach not only aids in executing tasks more efficiently but also provides better structure and organization in coding architecture.\n",
      "\n",
      "### Key Takeaways:\n",
      "- **Clarity and Manageability**: Breaking down tasks improves clarity in execution.\n",
      "- **Efficiency**: Smaller tasks are typically quicker to complete.\n",
      "- **Structured Approach**: A well-defined file and class structure enhances maintainability and understandability.\n",
      "\n",
      "Through systematic implementation of task decomposition and utilizing prompting techniques such as CoT, developers can enhance both the quality of code and overall productivity.# Report on Task Decomposition in Software Development\n",
      "\n",
      "## Executive Summary\n",
      "Task decomposition is a critical practice in software development, especially when dealing with complex problems. This report will explore the concept of task decomposition, focusing on how it can improve problem-solving efficiency by breaking down larger tasks into more manageable components. We will discuss the Chain of Thought (CoT) prompting technique and its relevance, as well as the methodology for creating a structured coding architecture that facilitates this process.\n",
      "\n",
      "## 1. Introduction to Task Decomposition\n",
      "Task decomposition refers to the systematic breakdown of a complex task into simpler, more manageable subtasks. This process not only simplifies the execution of the task but also clarifies the necessary steps and helps in planning and organizing the workflow.\n",
      "\n",
      "### 1.1 Importance\n",
      "- **Manageability**: Smaller tasks are easier to manage and keep track of.\n",
      "- **Clarity**: Decomposing tasks provides clear linear steps, making it easier for developers to understand the requirements.\n",
      "- **Cost and Time Efficiency**: Simplified tasks often require less time and fewer resources to complete.\n",
      "\n",
      "## 2. Chain of Thought (CoT) Prompting\n",
      "The Chain of Thought (CoT) prompting technique is a process designed to enhance a model's performance on complex tasks by encouraging step-by-step reasoning.\n",
      "\n",
      "### 2.1 How CoT Works\n",
      "- **Thinking Step by Step**: By breaking down tasks into smaller pieces, the model can better utilize its capabilities and reach accurate conclusions.\n",
      "- **Interpreting Models**: CoT provides insight into the model's thought processes, allowing developers to understand the decision-making criteria.\n",
      "\n",
      "### 2.2 Application in Task Decomposition\n",
      "- CoT can transform large, daunting tasks into smaller segments:\n",
      "  - Identify the main objective of the task.\n",
      "  - Divide that objective into key aspects.\n",
      "  - Break down those aspects into actionable steps.\n",
      "\n",
      "## 3. Implementation of Task Decomposition in Code Architecture\n",
      "To effectively implement task decomposition in code development, it is crucial to define core classes, functions, and methods that facilitate this process. \n",
      "\n",
      "### 3.1 Core Components\n",
      "The following are core components necessary for implementing a well-organized coding architecture:\n",
      "\n",
      "1. **Core Classes**:\n",
      "   - `TaskManager`: Manages and oversees the entire task decomposition process.\n",
      "   - `Subtask`: Represents a smaller component of a larger task.\n",
      "   - `TaskLogger`: Logs the progress and state of the tasks.\n",
      "\n",
      "2. **Core Methods**:\n",
      "   - `decompose_task(task)`: Takes a large task and returns a list of subtasks.\n",
      "   - `execute_subtask(subtask)`: Executes a given subtask and returns the result.\n",
      "   - `log_progress(task)`: Records the current state of task execution.\n",
      "\n",
      "### 3.2 Entrypoint Architecture\n",
      "The entrypoint architecture not only sets the requirements for task decomposition but also follows a specific file structure for organization.\n",
      "\n",
      "#### 3.2.1 File Structure Overview\n",
      "- `main.py`: The entrypoint of the application.\n",
      "- `task_manager.py`: Contains the `TaskManager` class and its methods.\n",
      "- `subtask.py`: Defines the `Subtask` class and its functionalities.\n",
      "- `task_logger.py`: Implements logging mechanisms.\n",
      "\n",
      "### 3.3 File Contents\n",
      "The actual code implementation follows a strict markdown format:\n",
      "\n",
      "#### 3.3.1 `main.py`\n",
      "```python\n",
      "# FILENAME: main.py\n",
      "# LANG: python\n",
      "\n",
      "from task_manager import TaskManager\n",
      "\n",
      "def main():\n",
      "    task = \"Implement a new feature\"\n",
      "    task_manager = TaskManager()\n",
      "    task_manager.decompose_task(task)\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "```\n",
      "\n",
      "#### 3.3.2 `task_manager.py`\n",
      "```python\n",
      "# FILENAME: task_manager.py\n",
      "# LANG: python\n",
      "\n",
      "class TaskManager:\n",
      "    def decompose_task(self, task):\n",
      "        # Logic for decomposing the task\n",
      "        print(f\"Decomposing task: {task}\")\n",
      "        # Return a list of subtasks\n",
      "        return [\"Subtask 1\", \"Subtask 2\"]\n",
      "\n",
      "    def execute_subtask(self, subtask):\n",
      "        # Logic for executing the subtask\n",
      "        print(f\"Executing {subtask}\")\n",
      "```\n",
      "\n",
      "#### 3.3.3 `subtask.py`\n",
      "```python\n",
      "# FILENAME: subtask.py\n",
      "# LANG: python\n",
      "\n",
      "class Subtask:\n",
      "    def __init__(self, name):\n",
      "        self.name = name\n",
      "    \n",
      "    def perform(self):\n",
      "        # Logic to perform the subtask\n",
      "        print(f\"Performing subtask: {self.name}\")\n",
      "```\n",
      "\n",
      "#### 3.3.4 `task_logger.py`\n",
      "```python\n",
      "# FILENAME: task_logger.py\n",
      "# LANG: python\n",
      "\n",
      "class TaskLogger:\n",
      "    def log_progress(self, task):\n",
      "        # Logic to log progress\n",
      "        print(f\"Logging progress for: {task}\")\n",
      "```\n",
      "\n",
      "## 4. Conclusion and Key Takeaways\n",
      "Task decomposition plays a vital role in software development, particularly for complex applications. The integration of Chain of Thought (CoT) reasoning can significantly enhance the process of breaking down tasks into simpler components. This approach not only aids in executing tasks more efficiently but also provides better structure and organization in coding architecture.\n",
      "\n",
      "### Key Takeaways:\n",
      "- **Clarity and Manageability**: Breaking down tasks improves clarity in execution.\n",
      "- **Efficiency**: Smaller tasks are typically quicker to complete.\n",
      "- **Structured Approach**: A well-defined file and class structure enhances maintainability and understandability.\n",
      "\n",
      "Through systematic implementation of task decomposition and utilizing prompting techniques such as CoT, developers can enhance both the quality of code and overall productivity.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"Generate a long length report on task decomposition. Use paragraphs and lists to make it more readable.\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 14 chunks from web content\n",
      "\n",
      "Document content: In support of its goals, the Committee decided to maintain the target range for the federal funds rate at 5-1/4 to 5-1/2 percent. In considering any adjustments to the target range for the federal funds rate, the Committee will carefully assess incoming data, the evolving outlook, and the balance of risks. The Committee does not expect it will be appropriate to reduce the target range until it has gained greater confidence that inflation is moving sustainably toward 2 percent. In addition, the Committee will continue reducing its holdings of Treasury securities and agency debt and agency mortgage-backed securities, as described in its previously announced plans. The Committee is strongly committed to returning inflation to its 2 percent objective.\n",
      "\n",
      "Metadata: {'title': 'Federal Reserve Board - Federal Reserve issues FOMC statement', 'source': 'https://www.federalreserve.gov/newsevents/pressreleases/monetary20240320a.htm', 'language': 'en', 'timestamp': '2025-02-13T18:16:04.694345', 'description': ' Recent indicators suggest that economic activity has been expanding at a solid pace. Job gains have remained strong, and the unemployment rate has remained low', 'source_type': 'news'}\n",
      "\n",
      "Document content: In support of its goals, the Committee decided to maintain the target range for the federal funds rate at 5-1/4 to 5-1/2 percent. In considering any adjustments to the target range for the federal funds rate, the Committee will carefully assess incoming data, the evolving outlook, and the balance of risks. The Committee does not expect it will be appropriate to reduce the target range until it has gained greater confidence that inflation is moving sustainably toward 2 percent. In addition, the Committee will continue reducing its holdings of Treasury securities and agency debt and agency mortgage-backed securities, as described in its previously announced plans. The Committee is strongly committed to returning inflation to its 2 percent objective.\n",
      "\n",
      "Metadata: {'title': 'Federal Reserve Board - Federal Reserve issues FOMC statement', 'source': 'https://www.federalreserve.gov/newsevents/pressreleases/monetary20240320a.htm', 'language': 'en', 'timestamp': '2025-02-13T15:56:02.294882', 'description': ' Recent indicators suggest that economic activity has been expanding at a solid pace. Job gains have remained strong, and the unemployment rate has remained low', 'source_type': 'news'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import SupabaseVectorStore\n",
    "from supabase import create_client\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "sys.path.append(\"../src\")  # Add the src directory to Python path\n",
    "from data.ingestion import DataIngestionPipeline\n",
    "\n",
    "# Initialize pipeline\n",
    "pipeline = DataIngestionPipeline()\n",
    "\n",
    "# Ingest Federal Reserve content\n",
    "urls = [\n",
    "    \"https://www.federalreserve.gov/newsevents/pressreleases/monetary20240320a.htm\",\n",
    "]\n",
    "num_chunks = pipeline.ingest_web_content(urls)\n",
    "print(f\"Processed {num_chunks} chunks from web content\")\n",
    "\n",
    "# Now your query about Fed rates should work\n",
    "docs = vector_store.similarity_search(\n",
    "    \"What was the Federal Reserve's latest decision on interest rates?\",\n",
    "    k=2\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for doc in docs:\n",
    "    print(\"\\nDocument content:\", doc.page_content)\n",
    "    print(\"\\nMetadata:\", doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Economic Report: Federal Reserve Monetary Policy Stance and Economic Outlook\n",
      "\n",
      "## Executive Summary\n",
      "\n",
      "The Federal Reserve's recent monetary policy decisions indicate a commitment to maintaining a cautious approach amid evolving economic conditions. With a sustained target range for the federal funds rate at 5-1/4 to 5-1/2 percent, the Fed's strategy reflects its ongoing mission to achieve maximum employment while managing inflation at the 2 percent target over the longer term. Key indicators suggest solid economic expansion; however, the Fed remains vigilant regarding rising inflation risks. The following sections analyze the current economic environment, the Federal Open Market Committee's (FOMC) decisions, and future policy implications.\n",
      "\n",
      "## Economic Activity and Labor Market Conditions\n",
      "\n",
      "Recent reports indicate that economic activity is expanding at a solid pace. Job gains remain robust, keeping the unemployment rate low. This labor market strength is crucial as it supports consumer spending and overall economic resilience. The Fed appears to view these positive labor indicators as foundational to achieving its dual mandate of maximum employment and price stability.\n",
      "\n",
      "### Key Data Points:\n",
      "- **Unemployment Rate**: Remains low, indicative of tight labor market conditions.\n",
      "- **Job Gains**: Strong, contributing to overall economic growth.\n",
      "\n",
      "## Inflation Trends and Risks\n",
      "\n",
      "While inflation has eased over the past year, it remains elevated, suspended above the Fed's target. The FOMC acknowledges that despite progress, inflation pressures persist, necessitating ongoing assessment of economic conditions to mitigate potential risks. The Committee's emphasis on balanced assessments of risks reveals its careful consideration of how varied economic factors interplay with inflation.\n",
      "\n",
      "### Inflation Metrics:\n",
      "- **Current Inflation Levels**: Elevated, but showing signs of easing.\n",
      "- **Fed’s Target Inflation Rate**: 2 percent, with ongoing commitment to returning to this level.\n",
      "\n",
      "## Monetary Policy Decisions and Outlook\n",
      "\n",
      "The Committee has decided to maintain the existing target range for the federal funds rate, reflecting a cautious stance underpinned by economic data. The Fed is prepared to adjust monetary policy should risks threaten its employment and inflation goals. In its current position, the FOMC does not foresee appropriate conditions for reducing the target range until there is greater clarity on inflation moving steadily toward 2 percent.\n",
      "\n",
      "### Policy Actions:\n",
      "- **Federal Funds Rate**: Held steady at 5-1/4 to 5-1/2 percent.\n",
      "- **Asset Reductions**: Continued reduction of Treasury securities and agency debt holdings in alignment with prior announcements.\n",
      "\n",
      "## Forward Guidance and Policy Implications\n",
      "\n",
      "The Fed's forward guidance indicates that it will closely monitor incoming economic data and adjust its policies accordingly. The current economic outlook presents uncertainties, primarily regarding inflation. The commitment to reduce holdings of securities suggests an ongoing alignment with contractionary monetary policy, aimed at stabilizing inflation expectations while managing market liquidity.\n",
      "\n",
      "### Implications:\n",
      "- **Risk Management**: Vigilance toward inflation risks remains a priority for future adjustments.\n",
      "- **Continued Monitoring**: The Fed will evaluate labor market conditions, inflation pressures, and other macroeconomic developments in future policy meetings.\n",
      "\n",
      "## Conclusion: Key Takeaways\n",
      "\n",
      "1. **Solid Economic Expansion**: The economy is showing signs of solid growth, with strong job gains and a low unemployment rate.\n",
      "2. **Inflation Vigilance**: Despite easing inflation, it remains elevated; the Fed is committed to achieving the 2 percent target without premature rate reductions.\n",
      "3. **Cautious Policy Implementation**: The current stance reflects a careful approach given the uncertainties in the economic outlook, emphasizing risk monitoring.\n",
      "\n",
      "The Federal Reserve remains committed to achieving its dual mandate while navigating a complex economic landscape characterized by growth and inflation challenges. As economic conditions evolve, the Fed's readiness to adjust its policy stance will be critical to maintaining stability.\n"
     ]
    }
   ],
   "source": [
    "# Create a report-focused prompt template\n",
    "report_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert economic analyst tasked with creating comprehensive reports. When generating reports:\n",
    "    - Start with a brief executive summary\n",
    "    - Organize information into clear sections with headings\n",
    "    - Analyze the Fed's decisions and their implications\n",
    "    - Include relevant economic data points mentioned\n",
    "    - Discuss forward guidance and policy outlook\n",
    "    - Maintain a professional, analytical tone\n",
    "    - Conclude with key takeaways\n",
    "    \n",
    "    Base your report MOSTLY on the provided context.\"\"\"),\n",
    "    (\"human\", \"Using the following Fed statement context, generate a detailed economic report analyzing the current monetary policy stance and economic outlook:\\n\\nContext: {context}\")\n",
    "])\n",
    "\n",
    "# Get documents from vector store\n",
    "docs = vector_store.similarity_search(\n",
    "    \"Federal Reserve monetary policy stance and economic outlook\",\n",
    "    k=4  # Increase k to get more context\n",
    ")\n",
    "\n",
    "# Prepare context from documents\n",
    "context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Generate the report\n",
    "messages = report_prompt.invoke({\"context\": context})\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Economic Report on Monetary Policy Stance and Economic Outlook\n",
      "\n",
      "## Executive Summary\n",
      "The Federal Reserve's latest assessments reflect a cautious yet proactive approach to current monetary policy, maintaining the federal funds rate target range between 5.25% and 5.50%. The Committee's focus remains on achieving maximum employment and an inflation rate of 2% over the longer term. Economic activity is expanding with strong job growth, while inflation has softened but remains above target levels. The forward guidance indicates that the Fed will adjust its policies based on incoming data and risk assessments, emphasizing continued vigilance regarding inflation pressures.\n",
      "\n",
      "## Current Monetary Policy Stance\n",
      "\n",
      "### Interest Rate Decision\n",
      "The Federal Open Market Committee (FOMC) has decided to keep the target range for the federal funds rate at 5.25% to 5.50%. This decision reflects a balanced approach to managing inflation while fostering economic growth. The Committee explicitly indicated that it will refrain from reducing interest rates until there is convincing evidence of sustainable progress towards the 2% inflation goal.\n",
      "\n",
      "### Ongoing Asset Holdings Reduction\n",
      "In tandem with holding interest rates steady, the Committee will continue to reduce its balance sheet, focusing on Treasury securities, agency debt, and agency mortgage-backed securities. This process is aimed at tightening monetary conditions gradually while ensuring financial stability.\n",
      "\n",
      "## Economic Conditions\n",
      "\n",
      "### Labor Market Insights\n",
      "Recent labor market indicators point to robust job gains and a maintained low unemployment rate. This growth suggests that the labor market is healthy and contributes positively to overall economic activity. However, the Committee recognizes the importance of not only job creation but also wage growth and labor force participation rates to sustain this upward trajectory.\n",
      "\n",
      "### Inflation Dynamics\n",
      "Inflation has shown signs of easing over the past year, yet it remains elevated relative to the Fed's targeted rate. The Committee is closely monitoring inflation pressures and expectations, acknowledging persistent uncertainties that can potentially disrupt their goals. This careful observation reflects a shift towards a more balanced risk assessment in relation to achieving stable prices and full employment.\n",
      "\n",
      "## Assessment of Risks and Outlook\n",
      "\n",
      "### Balancing Risks to Goals\n",
      "The FOMC’s statement reflects a favorable shift in the balance of risks toward achieving the dual mandate of maximum employment and stable inflation. Nonetheless, the uncertainty surrounding the economic outlook continues to be a primary concern. The Committee emphasizes its readiness to adjust monetary policy should emerging risks threaten to derail progress.\n",
      "\n",
      "### Long-Term Inflation Strategy\n",
      "The commitment to returning inflation to the 2% objective underscores the Fed's priority on price stability. By refraining from immediate rate cuts and maintaining a proactive stance, the FOMC aims to instill confidence in financial markets and the broader economy about its dedication to controlling inflation.\n",
      "\n",
      "## Forward Guidance and Policy Outlook\n",
      "\n",
      "### Adjustments to Policy\n",
      "The Fed remains prepared to adjust its monetary stance depending on evolving economic indicators and assessed risks. The guidance implies a data-driven approach, suggesting that potential future rate adjustments will be contingent on clear signs of sustainable economic stabilization and inflation moderation.\n",
      "\n",
      "### Monitoring Economic Developments\n",
      "The Committee's ongoing assessment will take into account diverse information streams, including labor market conditions, inflation trajectories, and global financial developments. This comprehensive evaluation is critical for informed decision-making about monetary policy interventions.\n",
      "\n",
      "## Key Takeaways\n",
      "- The FOMC maintains the federal funds rate target range at 5.25%-5.50%, keeping rates steady while monitoring inflation closely.\n",
      "- Economic activity remains solid with strong job gains, but inflation, though easing, is still above the desired target.\n",
      "- The Fed is committed to a balanced risk assessment framework, indicating readiness to adjust policies to achieve its dual mandates.\n",
      "- Ongoing asset holdings reduction reflects a gradual tightening approach, ensuring that inflation control remains a priority.\n",
      "- Future monetary policy will be dictated by a careful analysis of incoming economic data, emphasizing a commitment to transparency and adaptability.\n",
      "\n",
      "In conclusion, the Federal Reserve’s current monetary policy reflects cautious optimism, underpinned by solid labor market performance and proactive inflation management strategies. The commitment to a stable economic outlook will require ongoing vigilance and responsiveness to changes in economic conditions.\n"
     ]
    }
   ],
   "source": [
    "# Create a report-focused prompt template\n",
    "report_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert economic analyst tasked with creating comprehensive reports. When generating reports:\n",
    "    - Start with a brief executive summary\n",
    "    - Organize information into clear sections with headings\n",
    "    - Analyze the Fed's decisions and their implications\n",
    "    - Include relevant economic data points mentioned\n",
    "    - Discuss forward guidance and policy outlook\n",
    "    - Maintain a professional, analytical tone\n",
    "    - Conclude with key takeaways\n",
    "    \n",
    "    Base your report MOSTLY on the provided context.\"\"\"),\n",
    "    (\"human\", \"Generate a detailed economic report analyzing the current monetary policy stance and economic outlook:\\n\\nContext: {context}\")\n",
    "])\n",
    "\n",
    "# Get documents from vector store\n",
    "docs = vector_store.similarity_search(\n",
    "    \"Federal Reserve monetary policy stance and economic outlook\",\n",
    "    k=4  # Increase k to get more context\n",
    ")\n",
    "\n",
    "# Prepare context from documents\n",
    "context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Generate the report\n",
    "messages = report_prompt.invoke({\"context\": context})\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch starting at 0, got 287 chunks\n",
      "Processed batch starting at 5, got 287 chunks\n",
      "Processed batch starting at 10, got 287 chunks\n",
      "Processed batch starting at 15, got 287 chunks\n",
      "Processed batch starting at 20, got 287 chunks\n",
      "Processed batch starting at 25, got 287 chunks\n",
      "Processed batch starting at 30, got 287 chunks\n",
      "Processed batch starting at 35, got 287 chunks\n",
      "Processed batch starting at 40, got 287 chunks\n",
      "Processed batch starting at 45, got 287 chunks\n",
      "Processed batch starting at 50, got 287 chunks\n",
      "Processed batch starting at 55, got 287 chunks\n",
      "Processed batch starting at 60, got 287 chunks\n",
      "Processed batch starting at 65, got 287 chunks\n",
      "Processed batch starting at 70, got 287 chunks\n",
      "Processed batch starting at 75, got 287 chunks\n",
      "Processed batch starting at 80, got 287 chunks\n",
      "Processed batch starting at 85, got 287 chunks\n",
      "Processed batch starting at 90, got 287 chunks\n",
      "Processed batch starting at 95, got 287 chunks\n",
      "Processed total of 5740 chunks from Gmail\n"
     ]
    },
    {
     "ename": "APIError",
     "evalue": "{'code': '57014', 'details': None, 'hint': None, 'message': 'canceling statement due to statement timeout'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 77\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_chunks\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m chunks from Gmail\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Test retrieval with a market-related query\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mvector_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat are the latest market updates and economic indicators?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\n\u001b[1;32m     80\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Prepare context from documents\u001b[39;00m\n\u001b[1;32m     83\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs)\n",
      "File \u001b[0;32m~/Code/Rain/.venv/lib/python3.11/site-packages/langchain_community/vectorstores/supabase.py:184\u001b[0m, in \u001b[0;36mSupabaseVectorStore.similarity_search\u001b[0;34m(self, query, k, filter, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    178\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    182\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    183\u001b[0m     vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding\u001b[38;5;241m.\u001b[39membed_query(query)\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_by_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/Rain/.venv/lib/python3.11/site-packages/langchain_community/vectorstores/supabase.py:193\u001b[0m, in \u001b[0;36mSupabaseVectorStore.similarity_search_by_vector\u001b[0;34m(self, embedding, k, filter, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msimilarity_search_by_vector\u001b[39m(\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    188\u001b[0m     embedding: List[\u001b[38;5;28mfloat\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    192\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m--> 193\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_by_vector_with_relevance_scores\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     documents \u001b[38;5;241m=\u001b[39m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m result]\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m documents\n",
      "File \u001b[0;32m~/Code/Rain/.venv/lib/python3.11/site-packages/langchain_community/vectorstores/supabase.py:255\u001b[0m, in \u001b[0;36mSupabaseVectorStore.similarity_search_by_vector_with_relevance_scores\u001b[0;34m(self, query, k, filter, postgrest_filter, score_threshold)\u001b[0m\n\u001b[1;32m    249\u001b[0m     query_builder\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m query_builder\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mset(\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpostgrest_filter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m     )\n\u001b[1;32m    253\u001b[0m query_builder\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m query_builder\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit\u001b[39m\u001b[38;5;124m\"\u001b[39m, k)\n\u001b[0;32m--> 255\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mquery_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m match_result \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    258\u001b[0m     (\n\u001b[1;32m    259\u001b[0m         Document(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m search\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    267\u001b[0m ]\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m score_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Code/Rain/.venv/lib/python3.11/site-packages/postgrest/_sync/request_builder.py:127\u001b[0m, in \u001b[0;36mSyncSingleRequestBuilder.execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m SingleAPIResponse[_ReturnT]\u001b[38;5;241m.\u001b[39mfrom_http_request_response(r)\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m APIError(r\u001b[38;5;241m.\u001b[39mjson())\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIError(r\u001b[38;5;241m.\u001b[39mjson()) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mAPIError\u001b[0m: {'code': '57014', 'details': None, 'hint': None, 'message': 'canceling statement due to statement timeout'}"
     ]
    }
   ],
   "source": [
    "# Test Gmail ingestion\n",
    "from data.ingestion import DataIngestionPipeline\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import SupabaseVectorStore\n",
    "from supabase import create_client\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "report_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert economic analyst tasked with creating comprehensive reports. When generating reports:\n",
    "    - Start with a brief executive summary\n",
    "    - Organize information into clear sections with headings\n",
    "    - Analyze the Fed's decisions and their implications\n",
    "    - Include relevant economic data points mentioned\n",
    "    - Discuss forward guidance and policy outlook\n",
    "    - Maintain a professional, analytical tone\n",
    "    - Conclude with key takeaways\n",
    "    \n",
    "    Base your report MOSTLY on the provided context.\"\"\"),\n",
    "    (\"human\", \"Generate a detailed economic report analyzing the current monetary policy stance and economic outlook:\\n\\nContext: {context}\")\n",
    "])\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize core components\n",
    "supabase_url = os.getenv(\"SUPABASE_URL\")\n",
    "supabase_key = os.getenv(\"SUPABASE_SERVICE_KEY\")\n",
    "supabase_client = create_client(supabase_url, supabase_key)\n",
    "\n",
    "# Initialize LLM and embeddings\n",
    "llm = init_chat_model(\"gpt-4-turbo-preview\", model_provider=\"openai\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "vector_store = SupabaseVectorStore(\n",
    "    client=supabase_client,\n",
    "    embedding=embeddings,\n",
    "    table_name=\"documents\",\n",
    "    query_name=\"match_documents\"\n",
    ")\n",
    "\n",
    "# Initialize pipeline\n",
    "pipeline = DataIngestionPipeline()\n",
    "\n",
    "query = \"from:connie@strictlyvc.com OR from:fortune@newsletter.fortune.com OR from:anand.sanwal@cbinsights.com OR from:FT@newsletters.ft.com\"\n",
    "\n",
    "# Process in smaller batches with delay\n",
    "batch_size = 5  # Reduced batch size\n",
    "delay_between_batches = 2  # seconds\n",
    "total_chunks = 0\n",
    "\n",
    "try:\n",
    "    for start_index in range(0, 100, batch_size):\n",
    "        num_chunks = pipeline.ingest_gmail(\n",
    "            credentials_path='credentials.json',\n",
    "            query=query,\n",
    "            max_results=batch_size,\n",
    "            metadata={\"batch_start\": start_index}\n",
    "        )\n",
    "        total_chunks += num_chunks\n",
    "        print(f\"Processed batch starting at {start_index}, got {num_chunks} chunks\")\n",
    "        \n",
    "        # Add delay between batches\n",
    "        time.sleep(delay_between_batches)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error occurred at batch {start_index}: {str(e)}\")\n",
    "    \n",
    "print(f\"Processed total of {total_chunks} chunks from Gmail\")\n",
    "\n",
    "\n",
    "# Test retrieval with a market-related query\n",
    "docs = vector_store.similarity_search(\n",
    "    \"What are the latest market updates and economic indicators?\",\n",
    "    k=3\n",
    ")\n",
    "\n",
    "# Prepare context from documents\n",
    "context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Generate the report\n",
    "messages = report_prompt.invoke({\"context\": context})\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(response.content)\n",
    "\n",
    "print(\"\\nRetrieved Documents:\")\n",
    "count = 0\n",
    "for doc in docs:\n",
    "    count += 1\n",
    "    print(\"\\nDocument content:\", doc.page_content)\n",
    "    print(\"\\nMetadata:\", doc.metadata)\n",
    "\n",
    "print(f\"Processed {count} chunks from Gmail\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Executive Summary\n",
      "\n",
      "This analysis assesses the current market environment, incorporating the latest economic updates from Mexico and Colombia, impending earnings reports from Alphabet, KKR, and Pfizer, and global market metrics as of 0631 GMT-5. Given these conditions and our portfolio positions (Palantir, Snowflake, Meta, Apple, AMD, NVIDIA, TSMC, and SPY), we explore the implications of central bank policies, geopolitical risks, and market sentiment indicators to propose forward-looking scenarios and actionable trading implications.\n",
      "\n",
      "### Detailed Market Analysis\n",
      "\n",
      "#### Economic and Corporate Updates\n",
      "\n",
      "1. **Mexico and Colombia Economic Forecasts**:\n",
      "    - **Mexico**: The Bank of Mexico's updated GDP growth, inflation, exchange rate, and benchmark interest rate forecasts will provide insights into the economic health and policy trajectory of one of Latin America's largest economies. Higher-than-expected inflation or lower GDP growth forecasts could signal rising risks in emerging markets, potentially affecting global investor sentiment and risk appetites.\n",
      "    - **Colombia**: The release of the central bank's quarterly monetary policy report will shed light on potential adjustments in monetary policy that could impact capital flows in emerging markets.\n",
      "\n",
      "2. **Corporate Earnings**:\n",
      "    - **Alphabet (GOOGL)**, **KKR**, and **Pfizer (PFE)** are amongst the firms reporting. Alphabet's results will be particularly scrutinized for signs of advertising expenditure trends, which have broader implications for tech and media sectors, including companies like Meta in our portfolio.\n",
      "\n",
      "#### Global Market Metrics\n",
      "\n",
      "As of 0631 GMT-5, the key metrics to consider include:\n",
      "- **Volatility Measures (VIX, MOVE)**: Current levels and trends will impact our assessment of market sentiment and risk perception.\n",
      "- **Treasury Yields and Yield Curve Dynamics**: Movements here influence the valuation framework for equities, especially for growth and technology stocks in our portfolio.\n",
      "- **Credit Spreads and Financial Conditions**: Widening credit spreads could signal rising concerns about corporate indebtedness and economic stability.\n",
      "- **Commodity Prices**: Trends in commodities like oil and semiconductors could impact specific portfolio positions (e.g., TSMC, NVIDIA).\n",
      "\n",
      "#### Implications for Portfolio Positions\n",
      "\n",
      "1. **Growth and Tech Stocks (Palantir, Snowflake, Meta, Apple, AMD, NVIDIA, TSMC)**: \n",
      "    - These positions are sensitive to changes in Treasury yields, especially if inflation expectations drive yields higher. The monetary policy outlooks from Mexico and Colombia, although peripheral, can contribute to the global narrative on inflation and growth, influencing Fed policy expectations and thereby impacting these stocks.\n",
      "    - Alphabet's earnings could serve as a bellwether for the tech sector, especially for advertising-driven companies like Meta. Positive surprises could buoy the sector, while disappointments may lead to a reevaluation of growth prospects.\n",
      "\n",
      "2. **Broad Market Exposure (SPY)**:\n",
      "    - The SPDR S&P 500 ETF Trust (SPY) provides broad market exposure, making it vulnerable to shifts in macroeconomic indicators, central bank policies, and geopolitical risks. The economic forecasts from Mexico and Colombia, alongside the corporate earnings reports, could influence market sentiment broadly, impacting SPY.\n",
      "\n",
      "### Forward-Looking Scenarios\n",
      "\n",
      "1. **Optimistic Scenario (30% Probability)**: Better-than-expected earnings from Alphabet, KKR, and Pfizer, combined with positive economic forecasts from Mexico and Colombia, buoy market sentiment. Treasury yields remain stable, supporting growth and technology stocks. Our portfolio benefits, especially tech holdings.\n",
      "\n",
      "2. **Pessimistic Scenario (20% Probability)**: Disappointing earnings, coupled with negative economic projections, trigger a risk-off sentiment. Treasury yields rise sharply, pressuring valuations of growth and technology stocks. Diversification into SPY provides some buffer, but the portfolio faces downside pressure.\n",
      "\n",
      "3. **Base Case Scenario (50% Probability)**: Mixed economic data and earnings reports result in moderate market movements. Treasury yields rise modestly, but supportive financial conditions help balance portfolio risks. This scenario suggests maintaining current positions but being ready to adjust based on emerging data.\n",
      "\n",
      "### Actionable Trading Implications and Risk Management\n",
      "\n",
      "- **Maintain Current Positions** with a readiness to adjust based on emerging market dynamics and economic data.\n",
      "- **Monitor Treasury Yields and Corporate Earnings** closely, as these will provide early indications of whether a more defensively postured adjustment is warranted.\n",
      "- **Consider Hedging Strategies** for tech and growth positions if Treasury yields surge, using options for downside protection.\n",
      "- **Stay Informed** on geopolitical and central bank developments, which could swiftly change market sentiment and dynamics.\n",
      "\n",
      "### Specific Risks\n",
      "\n",
      "- **Rising Treasury Yields**: A sharper-than-expected rise could pressure high-valuation tech stocks.\n",
      "- **Geopolitical Risks**: Unforeseen events could rapidly shift market sentiment.\n",
      "\n",
      "By closely monitoring market metrics, economic indicators, and earnings reports, we can navigate the current environment with informed, strategic decisions, ready to capitalize on opportunities and mitigate risks.\n",
      "Retrieved Documents:\n",
      "\n",
      "Document content: the latest</a>. </p></li><li><p style=\"color:#000;font-family:Georgia,serif;font-size:18px;line-height:28px;margin:0 0 10px 0;padding:0 0 18px 0;clear:both\"><strong>Economic data:</strong> Mexico’s central bank will update its forecasts for the country’s GDP growth, inflation, exchange rate and benchmark interest rate. Colombia’s central bank is due to release its quarterly monetary policy report.</p></li><li><p style=\"color:#000;font-family:Georgia,serif;font-size:18px;line-height:28px;margin:0 0 10px 0;padding:0 0 18px 0;clear:both\"><strong>Results: </strong>Alphabet, KKR and Pfizer are among the companies reporting. See our <a\n",
      "\n",
      "Metadata: {'to': 'sc9423@stern.nyu.edu', 'date': 'Tue, 04 Feb 2025 11:31:12 +0000', 'from': 'FirstFT Americas <FT@newsletters.ft.com>', 'source': 'gmail', 'subject': 'China retaliates', 'timestamp': '2025-02-13T19:07:54.115647', 'message_id': '194d0ba96efc83d3', 'source_type': 'gmail'}\n",
      "\n",
      "Document content: style=\"margin:0 0 10px 0;width:100%;min-width:100%\"><tbody><tr><td height=\"1\" style=\"margin:0;padding:5px 0 0 0;font-size:0\">‌</td></tr><tr><td height=\"1\" style=\"padding:0 0 10px 0;font-size:0\"> <div style=\"border-top-color:#000;border-top-style:solid;border-top-width:1px;font-size:0;margin:0 0 2px 0\" class=\"dark-border-line-redesign\">‌</div> </td></tr><tr><td> <table width=\"100%\" border=\"0\" cellpadding=\"0\" cellspacing=\"0\" align=\"left\" style=\"margin:10px 0 0 0\"><tbody><tr><td style=\"padding:0 0 4px 0;text-align:left\"> <h3 style=\"color:#000;font-family:MetricWeb,Arial,sans-serif;font-size:24px;font-weight:500;line-height:28px;margin:0\" class=\"dark-heading\">Markets at <span style=\"color:#000;font-family:MetricWeb,Arial,sans-serif;font-size:24px;font-weight:500;line-height:28px;text-decoration:none\" class=\"dark-heading appleLink\"> 0631 GMT-5</span></h3> </td></tr></tbody></table> </td></tr><tr><td align=\"left\" valign=\"top\" style=\"width:100%;min-width:100%\"> <div class=\"dark-market-data\"\n",
      "\n",
      "Metadata: {'to': 'sc9423@stern.nyu.edu', 'date': 'Mon, 10 Feb 2025 11:31:56 +0000', 'from': 'FirstFT Americas <FT@newsletters.ft.com>', 'source': 'gmail', 'subject': 'A new burst of Trump protectionism', 'timestamp': '2025-02-13T19:22:40.513650', 'message_id': '194efa1b57e7c37a', 'batch_start': 0, 'source_type': 'gmail'}\n",
      "\n",
      "Document content: style=\"margin:0 0 10px 0;width:100%;min-width:100%\"><tbody><tr><td height=\"1\" style=\"margin:0;padding:5px 0 0 0;font-size:0\">‌</td></tr><tr><td height=\"1\" style=\"padding:0 0 10px 0;font-size:0\"> <div style=\"border-top-color:#000;border-top-style:solid;border-top-width:1px;font-size:0;margin:0 0 2px 0\" class=\"dark-border-line-redesign\">‌</div> </td></tr><tr><td> <table width=\"100%\" border=\"0\" cellpadding=\"0\" cellspacing=\"0\" align=\"left\" style=\"margin:10px 0 0 0\"><tbody><tr><td style=\"padding:0 0 4px 0;text-align:left\"> <h3 style=\"color:#000;font-family:MetricWeb,Arial,sans-serif;font-size:24px;font-weight:500;line-height:28px;margin:0\" class=\"dark-heading\">Markets at <span style=\"color:#000;font-family:MetricWeb,Arial,sans-serif;font-size:24px;font-weight:500;line-height:28px;text-decoration:none\" class=\"dark-heading appleLink\"> 0631 GMT-5</span></h3> </td></tr></tbody></table> </td></tr><tr><td align=\"left\" valign=\"top\" style=\"width:100%;min-width:100%\"> <div class=\"dark-market-data\"\n",
      "\n",
      "Metadata: {'to': 'sc9423@stern.nyu.edu', 'date': 'Mon, 10 Feb 2025 11:31:56 +0000', 'from': 'FirstFT Americas <FT@newsletters.ft.com>', 'source': 'gmail', 'subject': 'A new burst of Trump protectionism', 'timestamp': '2025-02-13T19:17:00.005510', 'message_id': '194efa1b57e7c37a', 'batch_start': 60, 'source_type': 'gmail'}\n"
     ]
    }
   ],
   "source": [
    "docs = vector_store.similarity_search(\n",
    "    \"What are the latest market updates and economic indicators?\",\n",
    "    k=3\n",
    ")\n",
    "\n",
    "report_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert macro and volatility analyst with deep experience in global markets, monetary policy, and risk analysis. When analyzing markets and responding to queries:\n",
    "\n",
    "- Start with key market metrics and indicators:\n",
    "  * VIX, MOVE, and other volatility measures\n",
    "  * Treasury yields and yield curve dynamics\n",
    "  * Credit spreads and financial conditions\n",
    "  * Currency movements and cross-asset correlations\n",
    "  * Commodity prices and trends\n",
    "\n",
    "- Provide detailed analysis of:\n",
    "  * Central bank policies and their market implications (Primarily the Fed)\n",
    "  * Geopolitical risks and their potential market impact\n",
    "  * Positioning data and market sentiment indicators\n",
    "  * Systematic flows and technical factors\n",
    "  * Cross-asset relationships and regime changes\n",
    "\n",
    "- Structure your responses with:\n",
    "  * Clear executive summary highlighting key points\n",
    "  * Detailed analysis backed by specific data points\n",
    "  * Forward-looking scenarios and their probabilities\n",
    "  * Specific risks to the current market narrative\n",
    "  * Actionable trading implications\n",
    "\n",
    "- Consider portfolio implications for current positions:\n",
    "  * Palantir, Snowflake, Meta, Apple, AMD, NVIDIA, TSMC, and SPY\n",
    "  * Impact on different asset classes and sectors\n",
    "  * Correlation changes and diversification effects\n",
    "  * Tail risk scenarios and hedging strategies\n",
    "  * Position sizing and risk management recommendations\n",
    "  * Time horizon considerations\n",
    "\n",
    "Base your analysis primarily on the provided context, but incorporate your broad market knowledge where relevant. Be specific rather than ambivalent - represent the views in the context. Maintain a professional, analytical tone and clearly distinguish between facts and opinions.\"\"\"),\n",
    "    (\"human\", \"Generate a detailed market analysis with specific implications for our portfolio positions:\\n\\nContext: {context}\")\n",
    "])\n",
    "\n",
    "\n",
    "# Prepare context from documents\n",
    "context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Generate the report\n",
    "messages = report_prompt.invoke({\"context\": context})\n",
    "stream = llm.stream(messages)\n",
    "\n",
    "# Process the streaming response\n",
    "response_content = \"\"\n",
    "for chunk in stream:\n",
    "    if chunk.content is not None:\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "        response_content += chunk.content\n",
    "\n",
    "print(\"\\nRetrieved Documents:\")\n",
    "count = 0\n",
    "for doc in docs:\n",
    "    count += 1\n",
    "    print(\"\\nDocument content:\", doc.page_content)\n",
    "    print(\"\\nMetadata:\", doc.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sid/Code/Rain/.venv/lib/python3.11/site-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chevron was the energy company that laid off 20% of its employees."
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "docs = vector_store.similarity_search(\n",
    "    \"Which energy company laid off 20% of its employees?\",\n",
    "    k=3\n",
    ")\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Modified prompt invocation\n",
    "messages = prompt.invoke({\n",
    "    \"context\": context,\n",
    "    \"question\": \"Which energy company laid off 20% of its employees?\"\n",
    "})\n",
    "response = llm.stream(messages)\n",
    "\n",
    "for chunk in response:\n",
    "    if chunk.content is not None:\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
